"""
Script ph√¢n t√≠ch d·ªØ li·ªáu thi·∫øu trong OUTPUT_MAU_2C_DOCXTPL.docx
"""

from docx import Document
import re
from pathlib import Path

def analyze_missing_data():
    """
    Ph√¢n t√≠ch v√† th·ªëng k√™ nh·ªØng tr∆∞·ªùng n√†o c√≤n thi·∫øu d·ªØ li·ªáu
    """
    
    print("üîç PH√ÇN T√çCH D·ªÆ LI·ªÜU THI·∫æU TRONG OUTPUT")
    print("="*80)
    
    doc_path = Path("OUTPUT_MAU_2C_DOCXTPL.docx")
    if not doc_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y {doc_path}")
        return
    
    doc = Document(doc_path)
    
    # Pattern ƒë·ªÉ t√¨m tr∆∞·ªùng thi·∫øu d·ªØ li·ªáu
    patterns = {
        'dots_3': r'\.{3,}',  # 3+ dots
        'dots_unicode': r'‚Ä¶{2,}',  # 2+ unicode dots
        'mixed': r'[\.‚Ä¶]{3,}',  # Mixed dots
        'colon_dots': r':\s*[\.‚Ä¶]{3,}',  # ": ..."
        'parentheses_dots': r'\([\.‚Ä¶]{3,}\)',  # "(...)"
    }
    
    missing_fields = []
    field_count = 0
    
    print("\nüìã PH√ÇN T√çCH PARAGRAPHS:")
    print("-"*80)
    
    for i, para in enumerate(doc.paragraphs):
        text = para.text.strip()
        if not text:
            continue
        
        # T√¨m c√°c pattern thi·∫øu d·ªØ li·ªáu
        has_missing = False
        missing_types = []
        
        for pattern_name, pattern in patterns.items():
            matches = re.findall(pattern, text)
            if matches:
                has_missing = True
                missing_types.append(f"{pattern_name}({len(matches)})")
        
        if has_missing:
            field_count += 1
            # T√¨m t√™n field (text tr∆∞·ªõc d·∫•u ":")
            field_name = text.split(':')[0] if ':' in text else text[:50]
            
            missing_fields.append({
                'index': i + 1,
                'field_name': field_name,
                'text': text[:100] + ('...' if len(text) > 100 else ''),
                'missing_types': ', '.join(missing_types)
            })
            
            print(f"\n‚ùå Para {i+1}: {field_name}")
            print(f"   Text: {text[:80]}...")
            print(f"   Thi·∫øu: {', '.join(missing_types)}")
    
    # Ph√¢n t√≠ch tables
    print("\n\nüìä PH√ÇN T√çCH TABLES:")
    print("-"*80)
    
    table_missing = []
    
    for table_idx, table in enumerate(doc.tables):
        print(f"\nüìã B·∫£ng {table_idx + 1}: {len(table.rows)}x{len(table.columns)}")
        
        for row_idx, row in enumerate(table.rows):
            for col_idx, cell in enumerate(row.cells):
                text = cell.text.strip()
                
                # Check if cell has missing data
                has_missing = False
                for pattern in patterns.values():
                    if re.search(pattern, text):
                        has_missing = True
                        break
                
                if has_missing and text:
                    table_missing.append({
                        'table': table_idx + 1,
                        'row': row_idx + 1,
                        'col': col_idx + 1,
                        'text': text[:50]
                    })
                    print(f"   ‚ùå Cell [{row_idx+1},{col_idx+1}]: {text[:50]}...")
    
    # Summary
    print("\n\n" + "="*80)
    print("üìä T·ªîNG K·∫æT:")
    print("="*80)
    print(f"\n‚úÖ T·ªïng paragraphs c√≥ d·ªØ li·ªáu: {len([p for p in doc.paragraphs if p.text.strip()])}")
    print(f"‚ùå Paragraphs thi·∫øu d·ªØ li·ªáu: {field_count}")
    print(f"‚ùå Table cells thi·∫øu d·ªØ li·ªáu: {len(table_missing)}")
    
    # Group by section
    print("\n\nüìã DANH S√ÅCH FIELDS THI·∫æU D·ªÆ LI·ªÜU:")
    print("-"*80)
    
    # Extract field names
    field_names = []
    for item in missing_fields:
        text = item['field_name']
        
        # Extract meaningful field name
        if ')' in text:
            # "1) H·ªç v√† t√™n: ..." ‚Üí "H·ªç v√† t√™n"
            field_name = text.split(')')[-1].strip().split(':')[0].strip()
        else:
            field_name = text.split(':')[0].strip()
        
        if field_name and len(field_name) > 3:
            field_names.append(field_name)
    
    # Remove duplicates and print
    unique_fields = []
    seen = set()
    for field in field_names:
        if field not in seen:
            unique_fields.append(field)
            seen.add(field)
    
    print(f"\nüî¢ T·ªïng c·ªông: {len(unique_fields)} fields thi·∫øu d·ªØ li·ªáu\n")
    
    for idx, field in enumerate(unique_fields, 1):
        print(f"{idx:2d}. {field}")
    
    # Suggest missing fields for JSON
    print("\n\nüí° G·ª¢I √ù TH√äM V√ÄO JSON:")
    print("-"*80)
    print("\nC√°c tr∆∞·ªùng c·∫ßn th√™m v√†o mau_2c_DATA_FULL.json:")
    print()
    
    suggested_json_fields = []
    
    # Map Vietnamese field names to JSON keys
    field_mapping = {
        'ƒê∆°n v·ªã tr·ª±c thu·ªôc': 'don_vi_truc_thuoc',
        'ƒê∆°n v·ªã c∆° s·ªü': 'don_vi_co_so',
        'S·ªë hi·ªáu': 'so_hieu',
        'Nam, n·ªØ': 'gioi_tinh',
        'C√°c t√™n g·ªçi kh√°c': 'ten_goi_khac',
        'C·∫•p ·ªßy hi·ªán t·∫°i': 'cap_uy_hien_tai',
        'C·∫•p ·ªßy ki√™m': 'cap_uy_kiem',
        'Ch·ª©c v·ª•': 'chuc_vu_full',
        'Ph·ª• c·∫•p ch·ª©c v·ª•': 'phu_cap_chuc_vu',
        'N∆°i sinh': 'noi_sinh',
        'Qu√™ qu√°n': 'que_quan',
        'N∆°i ·ªü hi·ªán nay': 'noi_o_hien_nay',
        'ƒë/tho·∫°i': 'dien_thoai',
        'D√¢n t·ªôc': 'dan_toc',
        'T√¥n gi√°o': 'ton_giao',
        'Th√†nh ph·∫ßn gia ƒë√¨nh xu·∫•t th√¢n': 'thanh_phan_xuat_than',
        'Ngh·ªÅ nghi·ªáp b·∫£n th√¢n': 'nghe_nghiep_ban_than',
        'Ng√†y ƒë∆∞·ª£c tuy·ªÉn d·ª•ng': 'ngay_tuyen_dung',
        'Ng√†y v√†o c∆° quan hi·ªán ƒëang c√¥ng t√°c': 'ngay_vao_co_quan',
        'Ng√†y tham gia c√°ch m·∫°ng': 'ngay_tham_gia_cach_mang',
        'Ng√†y ch√≠nh th·ª©c': 'ngay_chinh_thuc_dang',
        'Qu√¢n h√†m': 'quan_ham',
        'Tr√¨nh ƒë·ªô h·ªçc v·∫•n': 'trinh_do_hoc_van',
        'H·ªçc h√†m, h·ªçc v·ªã': 'hoc_ham_hoc_vi',
        'C√¥ng t√°c ch√≠nh ƒëang l√†m': 'cong_tac_chinh',
        'Ng·∫°ch c√¥ng ch·ª©c': 'ngach_cong_chuc',
        'B·∫≠c l∆∞∆°ng': 'bac_luong',
        'H·ªá s·ªë': 'he_so_luong',
        'Danh hi·ªáu ƒë∆∞·ª£c phong': 'danh_hieu',
        'S·ªü tr∆∞·ªùng c√¥ng t√°c': 'so_truong',
        'C√¥ng vi·ªác ƒë√£ l√†m l√¢u nh·∫•t': 'cong_viec_lau_nhat',
        'Khen th∆∞·ªüng': 'khen_thuong',
        'K·ª∑ lu·∫≠t': 'ky_luat',
        'T√¨nh tr·∫°ng s·ª©c kh·ªèe': 'suc_khoe',
        'Cao': 'chieu_cao',
        'C√¢n n·∫∑ng': 'can_nang',
        'Nh√≥m m√°u': 'nhom_mau',
        'S·ªë ch·ª©ng minh nh√¢n d√¢n': 'so_cmnd',
        'Th∆∞∆°ng binh lo·∫°i': 'thuong_binh',
        'Gia ƒë√¨nh li·ªát sƒ©': 'gia_dinh_liet_si',
    }
    
    for field in unique_fields:
        if field in field_mapping:
            json_key = field_mapping[field]
            suggested_json_fields.append(f'  "{json_key}": "",  # {field}')
    
    for suggestion in suggested_json_fields[:20]:  # First 20
        print(suggestion)
    
    if len(suggested_json_fields) > 20:
        print(f"\n... v√† {len(suggested_json_fields) - 20} fields kh√°c")
    
    print("\n\n" + "="*80)
    print("‚úÖ PH√ÇN T√çCH HO√ÄN T·∫§T!")
    print("="*80)

if __name__ == "__main__":
    try:
        analyze_missing_data()
    except Exception as e:
        print(f"\n‚ùå L·ªñI: {e}")
        import traceback
        traceback.print_exc()
